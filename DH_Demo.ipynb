{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DH Demo",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/secutron/ShowTime/blob/master/DH_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mf-UgvJOfYsQ",
        "colab_type": "text"
      },
      "source": [
        "## Code setup: Imports & methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fchxGDd90B0",
        "colab_type": "text"
      },
      "source": [
        "Get the classes and models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGMhIjnj90tF",
        "colab_type": "code",
        "outputId": "b0181cf4-bfa6-4c87-aa67-4e3333333464",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "!git clone https://github.com/26medias/keras-face-toolbox.git\n",
        "!mv keras-face-toolbox/models models\n",
        "!mv keras-face-toolbox/utils utils\n",
        "!rm -r keras-face-toolbox\n",
        "!gdown https://drive.google.com/uc?id=1H37LER8mRRI4q_nxpS3uQz3DcGHkTrNU\n",
        "!mv lresnet100e_ir_keras.h5 models/verifier/insightface/lresnet100e_ir_keras.h5"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'keras-face-toolbox'...\n",
            "remote: Enumerating objects: 76, done.\u001b[K\n",
            "remote: Counting objects: 100% (76/76), done.\u001b[K\n",
            "remote: Compressing objects: 100% (61/61), done.\u001b[K\n",
            "remote: Total 76 (delta 17), reused 72 (delta 13), pack-reused 0\n",
            "Unpacking objects: 100% (76/76), done.\n",
            "Checking out files: 100% (37/37), done.\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1H37LER8mRRI4q_nxpS3uQz3DcGHkTrNU\n",
            "To: /content/lresnet100e_ir_keras.h5\n",
            "262MB [00:01, 192MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LybUqjyadTEJ",
        "colab_type": "text"
      },
      "source": [
        "Pip install"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9J7chDuJwkP",
        "colab_type": "code",
        "outputId": "818ac927-c9c0-423b-e8a5-d1ed35b4b0e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!rm -r Faces/*"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'Faces/*': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNuNNoUEdR6L",
        "colab_type": "code",
        "outputId": "ec8fca44-4110-4ef7-91a0-f32d9a6a706f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install git+https://github.com/rcmalli/keras-vggface.git\n",
        "!pip show keras-vggface\n",
        "!pip install matplotlib\n",
        "!pip install mtcnn\n",
        "!pip install bs4\n",
        "!pip install selenium"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/rcmalli/keras-vggface.git\n",
            "  Cloning https://github.com/rcmalli/keras-vggface.git to /tmp/pip-req-build-crxp3wx1\n",
            "  Running command git clone -q https://github.com/rcmalli/keras-vggface.git /tmp/pip-req-build-crxp3wx1\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (1.16.4)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (1.3.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (2.8.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (4.3.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (2.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (1.12.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (3.13)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->keras-vggface==0.6) (0.46)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-vggface==0.6) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras->keras-vggface==0.6) (1.0.8)\n",
            "Building wheels for collected packages: keras-vggface\n",
            "  Building wheel for keras-vggface (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-vggface: filename=keras_vggface-0.6-cp36-none-any.whl size=8311 sha256=81ba0f3bd8a0f24ab389d003b577a91d5433b48710e3fd2745e7a2d456205393\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-hjrzc92f/wheels/36/07/46/06c25ce8e9cd396dabe151ea1d8a2bc28dafcb11321c1f3a6d\n",
            "Successfully built keras-vggface\n",
            "Installing collected packages: keras-vggface\n",
            "Successfully installed keras-vggface-0.6\n",
            "Name: keras-vggface\n",
            "Version: 0.6\n",
            "Summary: VGGFace implementation with Keras framework\n",
            "Home-page: https://github.com/rcmalli/keras-vggface\n",
            "Author: Refik Can MALLI\n",
            "Author-email: mallir@itu.edu.tr\n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: keras, six, scipy, pillow, h5py, pyyaml, numpy\n",
            "Required-by: \n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.0.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.2)\n",
            "Requirement already satisfied: numpy>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.16.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.5.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib) (41.2.0)\n",
            "Collecting mtcnn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/c7/8546b18fbd367b156c5bbbbaa8912ab31c8129171523ff8b47b546d70b09/mtcnn-0.0.9.tar.gz (2.3MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 2.8MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: mtcnn\n",
            "  Building wheel for mtcnn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mtcnn: filename=mtcnn-0.0.9-cp36-none-any.whl size=2257690 sha256=be9f1f22569243f41dca888c99fecf152568973cb6119b46bdc5cd08d3c454cd\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/81/65/6363fa5aafd7a155c896591e0c7c6e27b69642aa82b9cbf076\n",
            "Successfully built mtcnn\n",
            "Installing collected packages: mtcnn\n",
            "Successfully installed mtcnn-0.0.9\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.6/dist-packages (0.0.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from bs4) (4.6.3)\n",
            "Collecting selenium\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/d6/4294f0b4bce4de0abf13e17190289f9d0613b0a44e5dd6a7f5ca98459853/selenium-3.141.0-py2.py3-none-any.whl (904kB)\n",
            "\u001b[K     |████████████████████████████████| 911kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from selenium) (1.24.3)\n",
            "Installing collected packages: selenium\n",
            "Successfully installed selenium-3.141.0\n",
            "Collecting csv\n",
            "\u001b[31m  ERROR: Could not find a version that satisfies the requirement csv (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for csv\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BfU4qFBdSdo",
        "colab_type": "text"
      },
      "source": [
        "### Code\n",
        "\n",
        "#### Directory Structure\n",
        "\n",
        "- Videos\n",
        "  - [video_filename]\n",
        "- Faces\n",
        "  - [group_id]\n",
        "    - Faces\n",
        "    - Embeddings\n",
        "    - Landmarks\n",
        "    - Segmentations\n",
        "    - Previews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hD7jzfOIIJns",
        "colab_type": "code",
        "outputId": "7fb4f57f-4b70-4d48-d898-e38dad494a2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        }
      },
      "source": [
        "from IPython.display import HTML, display\n",
        "import time\n",
        "import requests\n",
        "import ntpath\n",
        "import cv2\n",
        "import math\n",
        "import os, sys\n",
        "from matplotlib import pyplot\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from numpy import asarray\n",
        "from scipy.spatial.distance import cosine\n",
        "from mtcnn.mtcnn import MTCNN\n",
        "import keras_vggface\n",
        "from keras_vggface.vggface import VGGFace\n",
        "from keras_vggface.utils import preprocess_input\n",
        "import glob\n",
        "import mtcnn\n",
        "from pathlib import Path\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from scipy.cluster import  hierarchy\n",
        "from bs4 import BeautifulSoup\n",
        "from selenium import webdriver\n",
        "import csv\n",
        "from models.detector import face_detector\n",
        "from models.parser import face_parser\n",
        "from utils.visualize import show_parsing_with_annos\n",
        "\n",
        "# Create the detector, using default weights\n",
        "print(\"Creating the detector model\")\n",
        "detector = MTCNN()\n",
        "\n",
        "# Create a vggface model\n",
        "print(\"Creating the face embedding model\")\n",
        "embedding_model = VGGFace(model='resnet50', include_top=False, input_shape=(224, 224, 3), pooling='avg')\n",
        "\n",
        "# Create a face detector\n",
        "print(\"Creating the face detector model\")\n",
        "fd = face_detector.FaceAlignmentDetector(lmd_weights_path=\"models/detector/FAN/2DFAN-4_keras.h5\")\n",
        "\n",
        "# Create a face parser (segmentation)\n",
        "print(\"Creating the face segmentation model\")\n",
        "prs = face_parser.FaceParser()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0904 04:04:54.808999 140485065951104 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/mtcnn/mtcnn.py:187: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0904 04:04:54.844135 140485065951104 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/mtcnn/mtcnn.py:193: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "landmark_detector FILE_PATH /content/models/detector\n",
            "face_detector FILE_PATH /content/models/detector\n",
            "Creating the detector model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0904 04:04:56.106729 140485065951104 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/mtcnn/network.py:43: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0904 04:04:56.108098 140485065951104 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/mtcnn/layer_factory.py:88: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0904 04:04:56.115648 140485065951104 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/mtcnn/layer_factory.py:79: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "W0904 04:04:56.117411 140485065951104 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0904 04:04:56.167286 140485065951104 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/mtcnn/layer_factory.py:171: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W0904 04:04:56.254748 140485065951104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/mtcnn/layer_factory.py:221: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "W0904 04:04:59.569771 140485065951104 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/mtcnn/layer_factory.py:196: The name tf.nn.xw_plus_b is deprecated. Please use tf.compat.v1.nn.xw_plus_b instead.\n",
            "\n",
            "W0904 04:05:00.620319 140485065951104 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Creating the face embedding model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0904 04:05:06.162803 140485065951104 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4271: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/rcmalli/keras-vggface/releases/download/v2.0/rcmalli_vggface_tf_notop_resnet50.h5\n",
            "94699520/94694792 [==============================] - 1s 0us/step\n",
            "Creating the face detector model\n",
            "Creating the face segmentation model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0904 04:05:14.120714 140485065951104 deprecation_wrapper.py:119] From /content/models/parser/BiSeNet/bisenet.py:56: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "W0904 04:05:14.783345 140485065951104 deprecation_wrapper.py:119] From /content/models/parser/BiSeNet/bisenet.py:58: The name tf.image.resize_bilinear is deprecated. Please use tf.compat.v1.image.resize_bilinear instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaQniUZYTVWk",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# The variables\n",
        "DIR_VIDEOS = \"Videos\"\n",
        "DIR_FACES = \"Faces\"\n",
        "CAPTURE_FPS  = 23 # We'll extract 1 images per second of video\n",
        "\n",
        "if not os.path.isdir(DIR_VIDEOS):\n",
        "  os.mkdir(DIR_VIDEOS, 755);\n",
        "if not os.path.isdir(DIR_FACES):\n",
        "  os.mkdir(DIR_FACES, 755);\n",
        "\n",
        "\n",
        "# Quick test mode\n",
        "TEST_MODE = False\n",
        "\n",
        "if TEST_MODE is True:\n",
        "  CAPTURE_FPS = 23\n",
        "\n",
        "# The methods\n",
        "# ===========\n",
        "\n",
        "# Colab progress bar\n",
        "def progress(value, max=100):\n",
        "    return HTML('<progress value=\"{value}\" max=\"{max}\" style=\"width: 50%\"> {value}</progress>'.format(value=value, max=max))\n",
        "\n",
        "# Convert a value from one range to another\n",
        "def rangeConvert(x, in_min, in_max, out_min, out_max):\n",
        "  return (x - in_min) * (out_max - out_min) / (in_max - in_min) + out_min\n",
        "\n",
        "# Get the directory of a filename\n",
        "def getDir(filename):\n",
        "  p = Path(filename);\n",
        "  return p.parts[len(p.parts)-2]\n",
        "\n",
        "# Dowload a video from a url\n",
        "def downloadFile(url):\n",
        "  print(\"Downloading \", url)\n",
        "  filename = DIR_VIDEOS+\"/\"+ntpath.basename(url)\n",
        "  if os.path.exists(filename):\n",
        "    return filename\n",
        "  myfile = requests.get(url)\n",
        "  open(filename, 'wb').write(myfile.content)\n",
        "  print(filename,\" downloaded.\")\n",
        "  return filename\n",
        "\n",
        "# Resize an image\n",
        "def resize_image(im, max_size=768):\n",
        "    if np.max(im.shape) > max_size:\n",
        "        ratio = max_size / np.max(im.shape)\n",
        "        print(f\"Resize image to ({str(int(im.shape[1]*ratio))}, {str(int(im.shape[0]*ratio))}).\")\n",
        "        return cv2.resize(im, (0,0), fx=ratio, fy=ratio)\n",
        "    return im\n",
        "\n",
        "\n",
        "def imageFilesToGrid(directory, outputFilename):\n",
        "  filenames = glob.glob(directory+'/*.jpg')\n",
        "  print(directory, \": \", len(filenames), \" images\")\n",
        "  if len(filenames) < 4:\n",
        "    return False\n",
        "  result_figsize_resolution = 10 # 1 = 100px\n",
        "  \n",
        "  images_count = len(filenames)\n",
        "  # Calculate the grid size:\n",
        "  grid_size = math.ceil(math.sqrt(images_count))\n",
        "  \n",
        "  # Create plt plot:\n",
        "  fig, axes = pyplot.subplots(grid_size, grid_size, figsize=(result_figsize_resolution, result_figsize_resolution))\n",
        "  \n",
        "  current_file_number = 0\n",
        "  for image_filename in filenames:\n",
        "      x_position = current_file_number % grid_size\n",
        "      y_position = current_file_number // grid_size\n",
        "      plt_image = pyplot.imread(image_filename)\n",
        "      axes[x_position, y_position].imshow(plt_image)\n",
        "      current_file_number += 1\n",
        "  pyplot.subplots_adjust(left=0.0, right=1.0, bottom=0.0, top=1.0)\n",
        "  pyplot.savefig(outputFilename)\n",
        "  #pyplot.show()\n",
        "\n",
        "def exportImageGrids(directory, outputDirectory):\n",
        "  print(\"Exporting image grids...\")\n",
        "  dirs = os.listdir(directory)\n",
        "  dirs.sort()\n",
        "  ndirs = len(dirs)\n",
        "  for n,dir in enumerate(dirs):\n",
        "    if dir is not \"ALL\":\n",
        "      imageFilesToGrid(directory+\"/\"+dir, outputDirectory+\"/\"+dir+\".jpg\");\n",
        "    progress(n, ndirs)\n",
        "\n",
        "# Extract the faces from an image, return an array of numpy faces\n",
        "def extractFacesFromImage(pixels, required_size=(224, 224), limit=50):\n",
        "  results = detector.detect_faces(pixels)\n",
        "  faces = []\n",
        "  errors = 0\n",
        "  for i,faceData in enumerate(results):\n",
        "    if len(faces) > limit:\n",
        "      break\n",
        "    x1, y1, width, height = faceData['box']\n",
        "    x2, y2 = x1 + width, y1 + height\n",
        "    # extract the face\n",
        "    face = pixels[y1:y2, x1:x2]\n",
        "    # resize pixels to the model size\n",
        "    try:\n",
        "      image = Image.fromarray(face)\n",
        "      image = image.resize(required_size)\n",
        "      face_array = asarray(image)\n",
        "      faces.append(face_array)\n",
        "      if limit==1:\n",
        "        return face_array\n",
        "    except:\n",
        "      errors+=1\n",
        "  if limit==1 and len(faces)==0:\n",
        "    return False\n",
        "  return faces;\n",
        "\n",
        "# Extract the faces from an image, return an array of numpy faces & landmarks\n",
        "def extractFacesAndLandmarksFromImage(pixels, required_size=(224, 224), limit=50):\n",
        "  rw, rh = required_size\n",
        "  results, landmarks = fd.detect_face(pixels, with_landmarks=True)\n",
        "  nResults = len(results)\n",
        "  faces = []\n",
        "  errors = 0\n",
        "  for i,bbox in enumerate(results):\n",
        "    if len(faces) > limit:\n",
        "      break\n",
        "    # Get the face\n",
        "    x0, y0, x1, y1, score = bbox\n",
        "    # Find the center of the face\n",
        "    w       = x1-x0\n",
        "    h       = y1-y0\n",
        "    xCenter = x0+int(w/2)\n",
        "    yCenter = y0+int(h/2)\n",
        "    if w>h:\n",
        "      y0 = yCenter-int(w/2)\n",
        "      y1 = yCenter+int(w/2)\n",
        "    if h>w:\n",
        "      x0 = xCenter-int(h/2)\n",
        "      x1 = xCenter+int(h/2)\n",
        "    x0, y0, x1, y1 = map(int, [x0, y0, x1, y1])\n",
        "    face = pixels[x0:x1, y0:y1, :]\n",
        "    # Recalculate the landmarks coordinates\n",
        "    for li in range(len(landmarks[i])): \n",
        "      landmark = landmarks[i][li]\n",
        "      lx, ly = landmark\n",
        "      landmarks[i][li] = (rangeConvert(lx-x0, 0, face.shape[1], 0, rw), rangeConvert(ly-y0, 0, face.shape[0], 0, rh))\n",
        "    # Resize pixels to the model size\n",
        "    try:\n",
        "      image = Image.fromarray(face)\n",
        "      image = image.resize(required_size)\n",
        "      face_array = asarray(image)\n",
        "      faces.append(face_array)\n",
        "      if limit==1:\n",
        "        return face_array\n",
        "    except:\n",
        "      errors+=1\n",
        "  if limit==1 and len(faces)==0:\n",
        "    return False\n",
        "  return faces, landmarks\n",
        "\n",
        "# Extract the faces from an image, return an array of numpy faces & landmarks\n",
        "def extractFacesLandmarksAndSegmentationFromImage(pixels, required_size=(224, 224), limit=50):\n",
        "  rw, rh = required_size\n",
        "  results, landmarks = fd.detect_face(pixels, with_landmarks=True)\n",
        "  nResults = len(results)\n",
        "  faces = []\n",
        "  segmentations = []\n",
        "  errors = 0\n",
        "  for i,bbox in enumerate(results):\n",
        "    if len(faces) > limit:\n",
        "      break\n",
        "    # Get the face\n",
        "    x0, y0, x1, y1, score = bbox\n",
        "    # Find the center of the face\n",
        "    w       = x1-x0\n",
        "    h       = y1-y0\n",
        "    xCenter = x0+int(w/2)\n",
        "    yCenter = y0+int(h/2)\n",
        "    if w>h:\n",
        "      y0 = yCenter-int(w/2)\n",
        "      y1 = yCenter+int(w/2)\n",
        "    if h>w:\n",
        "      x0 = xCenter-int(h/2)\n",
        "      x1 = xCenter+int(h/2)\n",
        "    x0, y0, x1, y1 = map(int, [x0, y0, x1, y1])\n",
        "    face = pixels[x0:x1, y0:y1, :]\n",
        "    # Recalculate the landmarks coordinates\n",
        "    for li in range(len(landmarks[i])): \n",
        "      landmark = landmarks[i][li]\n",
        "      lx, ly = landmark\n",
        "      landmarks[i][li] = (rangeConvert(lx-x0, 0, face.shape[1], 0, rw), rangeConvert(ly-y0, 0, face.shape[0], 0, rh))\n",
        "    # Resize pixels to the model size\n",
        "    try:\n",
        "      image = Image.fromarray(face)\n",
        "      image = image.resize(required_size)\n",
        "      face_array = asarray(image)\n",
        "      faces.append(face_array)\n",
        "      # Get the segmentation on the resized image\n",
        "      segmentation = prs.parse_face(face_array)\n",
        "      segmentations.append(segmentation)\n",
        "      if limit==1:\n",
        "        return face_array\n",
        "    except:\n",
        "      errors+=1\n",
        "  if limit==1 and len(faces)==0:\n",
        "    return False\n",
        "  return faces, landmarks, segmentations\n",
        "\n",
        "# Export the frames out of a video at a specific fps\n",
        "def videoToFaces(filename, skipFrame=10, maxFrame=0):\n",
        "  print(\"Extracting faces from the video frames...\")\n",
        "  basename = os.path.splitext(ntpath.basename(filename))[0]\n",
        "  #print(\"basename:\", basename)\n",
        "  cap = cv2.VideoCapture(filename)\n",
        "  # Get the video's FPS\n",
        "  fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "  nframes = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "  if TEST_MODE is True:\n",
        "    maxFrame = int(nframes/4)\n",
        "  processFrames = int(nframes/skipFrame)\n",
        "  print(basename, \": fps: \",fps, \"skipFrame:\",skipFrame,\" Frames: \", str(processFrames)+\"/\"+str(nframes))\n",
        "  out = display(progress(0, processFrames), display_id=True)\n",
        "  i = 0\n",
        "  c = 0\n",
        "  faces = []\n",
        "  landmarks = []\n",
        "  segmentations = []\n",
        "  while(cap.isOpened()):\n",
        "      ret, frame = cap.read()\n",
        "      if ret == False:\n",
        "          break\n",
        "      i+=1\n",
        "      if maxFrame>0 and i > maxFrame:\n",
        "        break;\n",
        "      #print(i, \"-\", i % skipFrame)\n",
        "      if (i % skipFrame == 0):\n",
        "        c+=1\n",
        "        #print(\"Checking faces in frame #\"+str(i))\n",
        "        #frameFaces = extractFacesFromImage(frame)\n",
        "        frameFaces, frameLandmarks, frameSegmentations = extractFacesLandmarksAndSegmentationFromImage(frame)\n",
        "        out.update(progress(c, processFrames))\n",
        "        for nf, f in enumerate(frameFaces):\n",
        "          faces.append(f)\n",
        "          landmarks.append(frameLandmarks[nf])\n",
        "          segmentations.append(frameSegmentations[nf])\n",
        "      else:\n",
        "        continue\n",
        "      #cv2.imwrite(DIR_IMAGES+\"/\"+basename+'/'+str(round((i-1)/fps,2))+'sec.jpg',frame)\n",
        "  cap.release()\n",
        "  cv2.destroyAllWindows()\n",
        "  print(basename, \" processed.\")\n",
        "  print(processFrames,\"/\",nframes,\" frames analyzed.\")\n",
        "  print(len(faces), \" faces found.\")\n",
        "  return faces, landmarks, segmentations\n",
        "\n",
        "\n",
        "# Show a few images\n",
        "def showImages(images, width=4):\n",
        "  fig = pyplot.figure(figsize=(width, math.ceil(len(images)/width)))\n",
        "  for i in range(len(images)):\n",
        "      pyplot.subplot(width, math.ceil(len(images)/width), i+1)\n",
        "      pyplot.imshow(images[i])\n",
        "      pyplot.axis('off')\n",
        "  pyplot.savefig('preview.png')\n",
        "  pyplot.show()\n",
        "\n",
        "# Save an array of images to files\n",
        "def saveImages(images, dest, names=False, prefix=\"\", showProgress=True):\n",
        "  if not os.path.isdir(dest):\n",
        "    os.mkdir(dest, 755);\n",
        "  nImages = len(images)\n",
        "  if showProgress is True:\n",
        "    print(\"Saving \",nImages,\" images to \", dest)\n",
        "    out = display(progress(0, nImages), display_id=True)\n",
        "  filenames = []\n",
        "  for n, image in enumerate(images):\n",
        "    if names is False:\n",
        "      filename = dest+\"/\"+prefix+('{:04d}'.format(n))+'.jpg'\n",
        "    else:\n",
        "      filename = dest+\"/\"+prefix+str(names[n])+'.jpg'\n",
        "    cv2.imwrite(filename, image)\n",
        "    filenames.append(filename)\n",
        "    if showProgress is True:\n",
        "      out.update(progress(n, nImages))\n",
        "  return filenames\n",
        "\n",
        "# Save Numpy Arrays to files\n",
        "def saveNpArrays(npArrays, dest, names=False, prefix=\"\", showProgress=True):\n",
        "  if not os.path.isdir(dest):\n",
        "    os.mkdir(dest, 755);\n",
        "  nArrays = len(npArrays)\n",
        "  if showProgress is True:\n",
        "    print(\"Saving \",nArrays,\" numpy arrays to \", dest)\n",
        "    out = display(progress(0, nArrays), display_id=True)\n",
        "  filenames = []\n",
        "  for n, npArray in enumerate(npArrays):\n",
        "    if names is False:\n",
        "      filename = dest+\"/\"+prefix+('{:04d}'.format(n))+'.npy'\n",
        "    else:\n",
        "      filename = dest+\"/\"+prefix+str(names[n])+'.npy'\n",
        "    np.save(filename, npArray)\n",
        "    filenames.append(filename)\n",
        "    if showProgress is True:\n",
        "      out.update(progress(n, nArrays))\n",
        "  return filenames\n",
        "\n",
        "\n",
        "# Extract faces and calculate face embeddings for a list of photo files\n",
        "def get_embeddings(faces):\n",
        "  print(\"Calculating the embeddings...\")\n",
        "\t# convert into an array of samples\n",
        "  samples = asarray(faces, 'float32')\n",
        "  # prepare the face for the model, e.g. center pixels\n",
        "  samples = preprocess_input(samples, version=2)\n",
        "  # perform prediction\n",
        "  embeddings = embedding_model.predict(samples)\n",
        "  return embeddings\n",
        "\n",
        "\n",
        "# Determine if a candidate face is a match for a known face\n",
        "def is_match(known_embedding, candidate_embedding, threshold=0.5):\n",
        "  # calculate distance between embeddings\n",
        "  score = cosine(known_embedding, candidate_embedding)\n",
        "  return score >= threshold\n",
        "\n",
        "# Cluster the faces by cosine distance\n",
        "def clusterFaces(faces, embeddings, landmarks, segmentations):\n",
        "  groups = [] # Array of dict {faces:[], embeddings: []}\n",
        "  nFaces = len(faces)\n",
        "  print(\"Clustering \",nFaces,\" faces...\")\n",
        "  out = display(progress(0, nFaces), display_id=True)\n",
        "  # For each faces\n",
        "  for n, face in enumerate(faces):\n",
        "    out.update(progress(n, nFaces))\n",
        "    if len(groups)==0:\n",
        "      groups.append({\n",
        "        \"faces\":         [face],\n",
        "        \"names\":         [n],\n",
        "        \"embeddings\":    [embeddings[n]],\n",
        "        \"landmarks\":     [landmarks[n]],\n",
        "        \"segmentations\": [segmentations[n]]\n",
        "      })\n",
        "    else:\n",
        "      # Not the first face, match it against all the groups, see if the average of cosine distance match an existing face\n",
        "      scores = [] # array of dict {group: n, embeddings: []}\n",
        "      for g, group in enumerate(groups):\n",
        "        groupScores = []\n",
        "        for embedding in group[\"embeddings\"]:\n",
        "          groupScores.append(cosine(embedding, embeddings[n]))\n",
        "        score = np.mean(groupScores)\n",
        "        scores.append({\n",
        "            \"group\": g,\n",
        "            \"score\": score\n",
        "        })\n",
        "      # Sort the scores for each group by lowest score, check if that score is below the threshold\n",
        "      scores = sorted(scores, key = lambda i: i[\"score\"], reverse=False)\n",
        "      if scores[0][\"score\"] <= 0.5:\n",
        "        # Add to the existing group the face matches\n",
        "        groups[scores[0][\"group\"]][\"landmarks\"].append(landmarks[n])\n",
        "        groups[scores[0][\"group\"]][\"embeddings\"].append(embeddings[n])\n",
        "        groups[scores[0][\"group\"]][\"segmentations\"].append(segmentations[n])\n",
        "        groups[scores[0][\"group\"]][\"faces\"].append(face)\n",
        "        groups[scores[0][\"group\"]][\"names\"].append(n)\n",
        "        #print(\"[Matched] face #\", n, \" to group #\", scores[0][\"group\"], \"score:\", scores[0][\"score\"])\n",
        "      else:\n",
        "        groups.append({\n",
        "          \"faces\":       [face],\n",
        "          \"names\":       [n],\n",
        "          \"embeddings\":  [embeddings[n]],\n",
        "          \"landmarks\":   [landmarks[n]],\n",
        "        \"segmentations\": [segmentations[n]]\n",
        "        })\n",
        "        #print(\"[New face] face #\", n, \" / Best score:\", scores[0][\"score\"])\n",
        "  return groups;\n",
        "\n",
        "# Cluster all the faces from a remote video\n",
        "def clusterFacesOnVideo(url):\n",
        "  print(\"Processing \", url);\n",
        "  # Download the video\n",
        "  videoFilename = downloadFile(url)\n",
        "  \n",
        "  # Get the directories name for that video\n",
        "  # /Faces/[dirname]/Faces\n",
        "  # /Faces/[dirname]/Embeddings\n",
        "  # /Faces/[dirname]/Landmarks\n",
        "  # /Faces/[dirname]/Segmentations\n",
        "  # /Faces/[dirname]/Previews\n",
        "  dirname          = os.path.splitext(ntpath.basename(videoFilename))[0]\n",
        "  \n",
        "  dirClustered     = DIR_FACES+\"/\"+dirname\n",
        "  dirFaces         = dirClustered+\"/Faces/\"\n",
        "  dirEmbeddings    = dirClustered+\"/Embeddings/\"\n",
        "  dirLandmarks     = dirClustered+\"/Landmarks/\"\n",
        "  dirSegmentations = dirClustered+\"/Segmentations/\"\n",
        "  dirPreviews      = dirClustered+\"/Previews/\"\n",
        "  \n",
        "  if os.path.exists(dirPreviews):\n",
        "    # Video already processed, go to the next one\n",
        "    print(\"Video already processed.\")\n",
        "    #return False\n",
        "  \n",
        "  # Create the directories\n",
        "  if not os.path.isdir(dirClustered):\n",
        "    os.mkdir(dirClustered, 755);\n",
        "  if not os.path.isdir(dirFaces):\n",
        "    os.mkdir(dirFaces, 755);\n",
        "  if not os.path.isdir(dirEmbeddings):\n",
        "    os.mkdir(dirEmbeddings, 755);\n",
        "  if not os.path.isdir(dirLandmarks):\n",
        "    os.mkdir(dirLandmarks, 755);\n",
        "  if not os.path.isdir(dirSegmentations):\n",
        "    os.mkdir(dirSegmentations, 755);\n",
        "  if not os.path.isdir(dirPreviews):\n",
        "    os.mkdir(dirPreviews, 755);\n",
        "  \n",
        "  # Open a CSV to save the datasets\n",
        "  with open(dirClustered+\"/\"+dirname+\".csv\", \"w\") as csvfile:\n",
        "    fieldnames = [\"video_name\", \"face_group\", \"image_filename\", \"embeddings_filename\", \"landmarks_filename\"]\n",
        "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "    writer.writeheader()\n",
        "    \n",
        "    # Find the faces on the video\n",
        "    faces, landmarks, segmentations  = videoToFaces(videoFilename, CAPTURE_FPS)\n",
        "    nFaces       = len(faces)\n",
        "    print(nFaces,\" faces detected\")\n",
        "\n",
        "    # Get the embedding for all the faces\n",
        "    embeddings    = get_embeddings(faces)\n",
        "    \n",
        "    # Cluster the faces using cosine distance\n",
        "    clusters      = clusterFaces(faces, embeddings, landmarks, segmentations)\n",
        "    nClusters     = len(clusters)\n",
        "\n",
        "    # Export each face group\n",
        "    print(\"Saving \",nClusters,\" face clusters...\")\n",
        "    for n, group in enumerate(clusters):\n",
        "      \n",
        "      ngImg = len(group[\"faces\"])\n",
        "      ngEbd = len(group[\"embeddings\"])\n",
        "      ngldk = len(group[\"landmarks\"])\n",
        "      \n",
        "      # Save the face as an image\n",
        "      image_filenames      = saveImages(group[\"faces\"], dirFaces+\"/\"+('{:04d}'.format(n)), showProgress=False)\n",
        "      \n",
        "      # Save the embedding as a numpy array\n",
        "      embeddings_filenames = saveNpArrays(group[\"embeddings\"], dirEmbeddings+\"/\"+('{:04d}'.format(n)), showProgress=False)\n",
        "      \n",
        "      # Save the landmarks as a numpy array\n",
        "      landmarks_filenames  = saveNpArrays(group[\"landmarks\"], dirLandmarks+\"/\"+('{:04d}'.format(n)), showProgress=False)\n",
        "      \n",
        "      # Save the segmentations as a numpy array\n",
        "      image_filenames      = saveNpArrays(group[\"segmentations\"], dirSegmentations+\"/\"+('{:04d}'.format(n)), showProgress=False)\n",
        "      \n",
        "      \n",
        "      # Update the CSV\n",
        "      for i, image_filename in enumerate(image_filenames):\n",
        "        writer.writerow({\n",
        "            \"video_name\": dirname,\n",
        "            \"face_group\": n,\n",
        "            \"image_filename\": image_filename,\n",
        "            \"embeddings_filename\": embeddings_filenames[i],\n",
        "            \"landmarks_filename\": landmarks_filenames[i]\n",
        "        })\n",
        "\n",
        "\n",
        "    # Build grids to show each face groups\n",
        "    exportImageGrids(dirFaces, dirPreviews)\n",
        "\n",
        "\n",
        "def clusterFacesFromVideos(urls):\n",
        "  nUrls = len(urls)\n",
        "  for n,url in enumerate(urls):\n",
        "    clusterFacesOnVideo(url)\n",
        "\n",
        "def fetchAllHDVideos(url):\n",
        "  response = requests.get(url)\n",
        "  soup = BeautifulSoup(response.content, \"html5lib\")\n",
        "  links = soup.find_all('a')\n",
        "  videos = []\n",
        "  for tag in links:\n",
        "    link = tag.get('href', None)\n",
        "    if link is not None and 'h480p' in link:\n",
        "      videos.append(link)\n",
        "  return videos"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLgQisTn9epT",
        "colab_type": "text"
      },
      "source": [
        "## Execute on all the videos\n",
        "\n",
        "This is going to take a few days...\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wArceY3F9eIe",
        "colab_type": "code",
        "outputId": "0f3115c6-bba7-4a09-d4a5-2aef3445dcd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 849
        }
      },
      "source": [
        "\n",
        "# Fetch all the HD trailers by webscrapping the webpage\n",
        "vids = fetchAllHDVideos(\"https://www.davestrailerpage.co.uk/\")\n",
        "#vids = vids[:1] # Limit to the 1st video\n",
        "\n",
        "# Cluster the faces from a bunch of videos\n",
        "clusterFacesFromVideos(vids)\n",
        "\n",
        "# Save the faces\n",
        "!tar -zcf faces.tar.gz Faces\n",
        "\n",
        "# Upload to Cloud Storage\n",
        "!gcloud config set project deep-learning-files\n",
        "!gsutil cp  ./faces.tar.gz gs://tf-face-angle-translation/datasets/faces-clustered-very-large.tar.gz\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing  http://trailers.apple.com/movies/paramount/terminator-dark-fate/terminator-dark-fate-trailer-2_h480p.mov\n",
            "Downloading  http://trailers.apple.com/movies/paramount/terminator-dark-fate/terminator-dark-fate-trailer-2_h480p.mov\n",
            "Video already processed.\n",
            "Extracting faces from the video frames...\n",
            "terminator-dark-fate-trailer-2_h480p : fps:  23.976023976023978 skipFrame: 23  Frames:  164/3774\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<progress value=\"164\" max=\"164\" style=\"width: 50%\"> 164</progress>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in double_scalars\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "terminator-dark-fate-trailer-2_h480p  processed.\n",
            "164 / 3774  frames analyzed.\n",
            "111  faces found.\n",
            "111  faces detected\n",
            "Calculating the embeddings...\n",
            "Clustering  111  faces...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<progress value=\"110\" max=\"111\" style=\"width: 50%\"> 110</progress>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving  26  face clusters...\n",
            "Exporting image grids...\n",
            "Faces/terminator-dark-fate-trailer-2_h480p/Faces//0000 :  27  images\n",
            "Faces/terminator-dark-fate-trailer-2_h480p/Faces//0001 :  10  images\n",
            "Faces/terminator-dark-fate-trailer-2_h480p/Faces//0002 :  3  images\n",
            "Faces/terminator-dark-fate-trailer-2_h480p/Faces//0003 :  6  images\n",
            "Faces/terminator-dark-fate-trailer-2_h480p/Faces//0004 :  2  images\n",
            "Faces/terminator-dark-fate-trailer-2_h480p/Faces//0005 :  12  images\n",
            "Faces/terminator-dark-fate-trailer-2_h480p/Faces//0006 :  2  images\n",
            "Faces/terminator-dark-fate-trailer-2_h480p/Faces//0007 :  2  images\n",
            "Faces/terminator-dark-fate-trailer-2_h480p/Faces//0008 :  1  images\n",
            "Faces/terminator-dark-fate-trailer-2_h480p/Faces//0009 :  1  images\n",
            "Faces/terminator-dark-fate-trailer-2_h480p/Faces//0010 :  2  images\n",
            "Faces/terminator-dark-fate-trailer-2_h480p/Faces//0011 :  5  images\n",
            "Faces/terminator-dark-fate-trailer-2_h480p/Faces//0012 :  10  images\n",
            "Faces/terminator-dark-fate-trailer-2_h480p/Faces//0013 :  2  images\n",
            "Faces/terminator-dark-fate-trailer-2_h480p/Faces//0014 :  1  images\n",
            "Faces/terminator-dark-fate-trailer-2_h480p/Faces//0015 :  2  images\n",
            "Faces/terminator-dark-fate-trailer-2_h480p/Faces//0016 :  8  images\n",
            "Faces/terminator-dark-fate-trailer-2_h480p/Faces//0017 :  4  images\n",
            "Faces/terminator-dark-fate-trailer-2_h480p/Faces//0018 :  1  images\n",
            "Faces/terminator-dark-fate-trailer-2_h480p/Faces//0019 :  2  images\n",
            "Faces/terminator-dark-fate-trailer-2_h480p/Faces//0020 :  1  images\n",
            "Faces/terminator-dark-fate-trailer-2_h480p/Faces//0021 :  1  images\n",
            "Faces/terminator-dark-fate-trailer-2_h480p/Faces//0022 :  2  images\n",
            "Faces/terminator-dark-fate-trailer-2_h480p/Faces//0023 :  2  images\n",
            "Faces/terminator-dark-fate-trailer-2_h480p/Faces//0024 :  1  images\n",
            "Faces/terminator-dark-fate-trailer-2_h480p/Faces//0025 :  1  images\n",
            "Processing  http://trailers.apple.com/movies/ifc_films/loro/loro-trailer-1_h480p.mov\n",
            "Downloading  http://trailers.apple.com/movies/ifc_films/loro/loro-trailer-1_h480p.mov\n",
            "Videos/loro-trailer-1_h480p.mov  downloaded.\n",
            "Extracting faces from the video frames...\n",
            "loro-trailer-1_h480p : fps:  24.0 skipFrame: 23  Frames:  146/3363\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<progress value=\"49\" max=\"146\" style=\"width: 50%\"> 49</progress>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}