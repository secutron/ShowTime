{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EDA steel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/secutron/ShowTime/blob/master/EDA_steel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfwXQ6XwFyCv",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3Ch9kfQbqbf",
        "colab_type": "text"
      },
      "source": [
        "## Connect with Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNRMqv4Yl38F",
        "colab_type": "code",
        "outputId": "11e58486-a39e-4544-c341-62cce9b70686",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laENh7RRb3An",
        "colab_type": "text"
      },
      "source": [
        "## Set Directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZpcGH6BmCk8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/My Drive/dataset/Steel/steel1/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iT5C1UupkDbI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!ls ./test_images/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwRYBDe1cKhv",
        "colab_type": "text"
      },
      "source": [
        "## Import required packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M350W7LvmD8Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers import Activation, Lambda, GlobalAveragePooling2D, concatenate\n",
        "from tensorflow.keras.layers import UpSampling2D, Conv2D, Dropout, MaxPooling2D, Conv2DTranspose\n",
        "from tensorflow.keras.layers import Dense, Flatten, Input\n",
        "from tensorflow.keras.models import Model, Sequential, load_model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "# from tensorflow.keras.applications.vgg16 import VGG16\n",
        "# from keras.applications.vgg16 import VGG16\n",
        "# from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_M1A244cOl3",
        "colab_type": "text"
      },
      "source": [
        "## Hyperparameters\n",
        "\n",
        "원영상 크기는 1600x256x24b"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7Cv_aPTmF8H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_size = 256\n",
        "IMG_HEIGHT = 400\n",
        "IMG_WIDTH = 1600\n",
        "epochs = 10\n",
        "batch_size = 4\n",
        "model_name = 'Training Segementaion Unet 09-10-19.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vZIQYZ0cTP3",
        "colab_type": "text"
      },
      "source": [
        "## Read csv for traning and validation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O70VYMNvPDim",
        "colab_type": "code",
        "outputId": "52e9bf63-2a1e-4c89-95d9-e98a57c8a638",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "tr = pd.read_csv('train.csv')\n",
        "tr.head()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ImageId</th>\n",
              "      <th>ClassId</th>\n",
              "      <th>EncodedPixels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0002cc93b.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>29102 12 29346 24 29602 24 29858 24 30114 24 3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0007a71bf.jpg</td>\n",
              "      <td>3</td>\n",
              "      <td>18661 28 18863 82 19091 110 19347 110 19603 11...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000a4bcdd.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>37607 3 37858 8 38108 14 38359 20 38610 25 388...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000f6bf48.jpg</td>\n",
              "      <td>4</td>\n",
              "      <td>131973 1 132228 4 132483 6 132738 8 132993 11 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0014fce06.jpg</td>\n",
              "      <td>3</td>\n",
              "      <td>229501 11 229741 33 229981 55 230221 77 230468...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         ImageId  ClassId                                      EncodedPixels\n",
              "0  0002cc93b.jpg        1  29102 12 29346 24 29602 24 29858 24 30114 24 3...\n",
              "1  0007a71bf.jpg        3  18661 28 18863 82 19091 110 19347 110 19603 11...\n",
              "2  000a4bcdd.jpg        1  37607 3 37858 8 38108 14 38359 20 38610 25 388...\n",
              "3  000f6bf48.jpg        4  131973 1 132228 4 132483 6 132738 8 132993 11 ...\n",
              "4  0014fce06.jpg        3  229501 11 229741 33 229981 55 230221 77 230468..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fd6-O2LHw1Z6",
        "colab_type": "code",
        "outputId": "7dce7a7a-16b8-4409-8efc-83485bacfea3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "tr.info()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7095 entries, 0 to 7094\n",
            "Data columns (total 3 columns):\n",
            " #   Column         Non-Null Count  Dtype \n",
            "---  ------         --------------  ----- \n",
            " 0   ImageId        7095 non-null   object\n",
            " 1   ClassId        7095 non-null   int64 \n",
            " 2   EncodedPixels  7095 non-null   object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 166.4+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6_hfl2eNEq3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "6483b54c-58c1-4ac3-b2af-b16460dc641b"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "def resize_image(im, max_size=768):\n",
        "    if np.max(im.shape) > max_size:\n",
        "        ratio = max_size / np.max(im.shape)\n",
        "        print(f\"Resize image to ({str(int(im.shape[1]*ratio))}, {str(int(im.shape[0]*ratio))}).\")\n",
        "        return cv2.resize(im, (0,0), fx=ratio, fy=ratio)\n",
        "    return im\n",
        "\n",
        "testshow = 'test_images/' + tr.iloc[0]['ImageId']\n",
        "print(testshow)\n",
        "\n",
        "# Test images are obtained on https://www.pexels.com/\n",
        "im = cv2.imread(testshow)[..., ::-1]\n",
        "im = resize_image(im) # Resize image to prevent GPU OOM.\n",
        "h, w, _ = im.shape\n",
        "plt.imshow(im)    "
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_images/0002cc93b.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-06bd9a6c04b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Test images are obtained on https://www.pexels.com/\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"images/test.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresize_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Resize image to prevent GPU OOM.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ff92uuUYmrOD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_count = defaultdict(int)\n",
        "\n",
        "for row in range(0, len(tr)):\n",
        "  labels = tr.iloc[row, 1]\n",
        "  class_count[labels] += 1;\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "sns.barplot(x=list(class_count.keys()), y=list(class_count.values()), ax=ax)\n",
        "ax.set_title(\"the number of images for each class\")\n",
        "ax.set_xlabel(\"class\")\n",
        "class_dict\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A674_CqWjbsF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLaIl796kTNr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEE5qilBmVSo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = tr[tr['EncodedPixels'].notnull()].reset_index(drop=True)\n",
        "df_train.head()\n",
        "\n",
        "#df_val = te[te['EncodedPixels'].notnull()].reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5O2nHh5cn1B",
        "colab_type": "text"
      },
      "source": [
        "## Runlength encoding for masking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "by8GVtximXex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rle2mask(rle, imgshape):\n",
        "    width = imgshape[0]\n",
        "    height= imgshape[1]\n",
        "    \n",
        "    mask= np.zeros( width*height ).astype(np.uint8)\n",
        "    \n",
        "    array = np.asarray([int(x) for x in rle.split()])\n",
        "    starts = array[0::2]\n",
        "    lengths = array[1::2]\n",
        "\n",
        "    current_position = 0\n",
        "    for index, start in enumerate(starts):\n",
        "        mask[int(start):int(start+lengths[index])] = 1\n",
        "        current_position += lengths[index]\n",
        "        \n",
        "    return np.flipud( np.rot90( mask.reshape(height, width), k=1 ) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVVvQaBLcwaS",
        "colab_type": "text"
      },
      "source": [
        "## Data Generator Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uz-nx2pYmZNI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def keras_generator_train(batch_size):\n",
        "    while True:\n",
        "        x_batch = []\n",
        "        img_cls_list = []\n",
        "        mask_list = []\n",
        "        classification_list = []\n",
        "        \n",
        "        for i in range(batch_size):            \n",
        "            fn = df_train['ImageId_ClassId'].iloc[i].split('_')[0]\n",
        "            img = cv2.imread('dataset/train_images/'+fn )\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  \n",
        "\n",
        "            # print(\"Shape: \", img.shape)          \n",
        "            \n",
        "            mask = rle2mask(df_train['EncodedPixels'].iloc[i], img.shape)\n",
        "            \n",
        "            # img = cv2.resize(img, (image_size, image_size))\n",
        "            # mask = cv2.resize(mask, (image_size, image_size))\n",
        "\n",
        "            img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n",
        "            mask = cv2.resize(mask, (IMG_WIDTH, IMG_HEIGHT))\n",
        "            mask = np.reshape(mask, (mask.shape[0], mask.shape[1], 1))\n",
        "\n",
        "            \n",
        "            # img_cls = df_train['ImageId_ClassId'].iloc[i].split('_')[1]\n",
        "            # if img_cls == '1':\n",
        "            #     img_cls_list = np.array([1, 0, 0, 0])\n",
        "            # elif img_cls == '2':\n",
        "            #     img_cls_list = np.array([0, 1, 0, 0])\n",
        "            # elif img_cls == '3':\n",
        "            #     img_cls_list = np.array([0, 0, 1, 0])\n",
        "            # else:\n",
        "            #     img_cls_list = np.array([0, 0, 0, 1])\n",
        "\n",
        "\n",
        "\n",
        "            x_batch.append(img)\n",
        "            mask_list.append(mask)\n",
        "            # classification_list.append(img_cls_list)\n",
        "        \n",
        "        y_batch = {'seg': np.array(mask_list),\n",
        "                #    'cls': np.array(classification_list)\n",
        "                }\n",
        "           \n",
        "        x_batch = np.array(x_batch)\n",
        "\n",
        "        yield x_batch, y_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CW0WJms3czop",
        "colab_type": "text"
      },
      "source": [
        "## Data Generator Valid"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edeX8uVBmbgw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def keras_generator_valid(batch_size):\n",
        "    while True:\n",
        "        x_batch = []\n",
        "        img_cls_list = []\n",
        "        mask_list = []\n",
        "        classification_list = []\n",
        "        \n",
        "        for i in range(batch_size):            \n",
        "            fn = df_val['ImageId_ClassId'].iloc[i].split('_')[0]\n",
        "            img = cv2.imread( 'dataset/valid_images/'+fn )\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)            \n",
        "            \n",
        "            mask = rle2mask(df_train['EncodedPixels'].iloc[i], img.shape)\n",
        "            \n",
        "            # img = cv2.resize(img, (image_size, image_size))\n",
        "            # mask = cv2.resize(mask, (image_size, image_size))\n",
        "\n",
        "            img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n",
        "            mask = cv2.resize(mask, (IMG_WIDTH, IMG_HEIGHT))\n",
        "\n",
        "            mask = np.reshape(mask, (mask.shape[0], mask.shape[1], 1))\n",
        "            \n",
        "            # img_cls = df_train['ImageId_ClassId'].iloc[i].split('_')[1]\n",
        "            # if img_cls == '1':\n",
        "            #     img_cls_list = np.array([1, 0, 0, 0])\n",
        "            # elif img_cls == '2':\n",
        "            #     img_cls_list = np.array([0, 1, 0, 0])\n",
        "            # elif img_cls == '3':\n",
        "            #     img_cls_list = np.array([0, 0, 1, 0])\n",
        "            # else:\n",
        "            #     img_cls_list = np.array([0, 0, 0, 1])\n",
        "            \n",
        "            x_batch.append(img)\n",
        "            mask_list.append(mask)\n",
        "            # classification_list.append(img_cls_list)\n",
        "        \n",
        "        y_batch = {'seg': np.array(mask_list),\n",
        "                #    'cls': np.array(classification_list)\n",
        "                }\n",
        "           \n",
        "        x_batch = np.array(x_batch)\n",
        "        \n",
        "        yield x_batch, y_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZXLgpSu8z7O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for xcls, ycls in keras_generator_train(5):\n",
        "    break\n",
        "    \n",
        "print(xcls.shape)\n",
        "print(ycls['seg'].shape)\n",
        "# print(ycls['cls'].shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXqTxKsEAZra",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for xcls, ycls in keras_generator_valid(5):\n",
        "    break\n",
        "    \n",
        "print(xcls.shape)\n",
        "print(ycls['seg'].shape)\n",
        "# print(ycls['cls'].shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8w9gtsHc7R6",
        "colab_type": "text"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuElNADYmcIB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# in1 = Input(shape=(image_size, image_size, 3 ))\n",
        "\n",
        "in1 = Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3 ))\n",
        "\n",
        "conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(in1)\n",
        "conv1 = Dropout(0.2)(conv1)\n",
        "conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
        "pool1 = MaxPooling2D((2, 2))(conv1)\n",
        "\n",
        "conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
        "conv2 = Dropout(0.2)(conv2)\n",
        "conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
        "pool2 = MaxPooling2D((2, 2))(conv2)\n",
        "\n",
        "conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
        "conv3 = Dropout(0.2)(conv3)\n",
        "conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
        "\n",
        "up1 = concatenate([UpSampling2D((2, 2))(conv3), conv2], axis=-1)\n",
        "conv4 = Conv2D(64, (3, 3), activation='relu', padding='same')(up1)\n",
        "conv4 = Dropout(0.2)(conv4)\n",
        "conv4 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv4)\n",
        "\n",
        "up2 = concatenate([UpSampling2D((2, 2))(conv4), conv1], axis=-1)\n",
        "conv5 = Conv2D(32, (3, 3), activation='relu', padding='same')(up2)\n",
        "conv5 = Dropout(0.2)(conv5)\n",
        "conv5 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv5)\n",
        "segmentation = Conv2D(1, (1, 1), activation='sigmoid', name='seg')(conv5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNQKPFBvmm6C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(inputs=[in1], outputs=[segmentation])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sVWwZuwc_dB",
        "colab_type": "text"
      },
      "source": [
        "## Parameters for compilation of model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uW8orbQFvSTx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "losses = {'seg': 'binary_crossentropy'\n",
        "            }\n",
        "\n",
        "metrics = {'seg': ['acc']\n",
        "            }\n",
        "\n",
        "# cls_w = {'seg': {0: 1.0, \n",
        "#                  1: 1.5647207819029325, \n",
        "#                  2: 1.0, \n",
        "#                  3: 1.0}\n",
        "#         }\n",
        "\n",
        "moni = {'seg': ['val_loss']\n",
        "        }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fzqirHhdGc5",
        "colab_type": "text"
      },
      "source": [
        "## Compile"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNbL_7Fwu02t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=\"adam\", loss = losses, metrics=metrics)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2FVTkVxdI0J",
        "colab_type": "text"
      },
      "source": [
        "## Fit Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDfwlREev7vO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "modelcheckpoint = ModelCheckpoint(model_name,\n",
        "                                  monitor='acc',\n",
        "                                  mode='auto',\n",
        "                                  verbose=1,\n",
        "                                  save_best_only=True)\n",
        "\n",
        "lr_callback = ReduceLROnPlateau(min_lr=0.000001)\n",
        "\n",
        "callback_list = [modelcheckpoint, lr_callback]\n",
        "\n",
        "history = model.fit_generator(\n",
        "    keras_generator_train(batch_size),\n",
        "    validation_data = keras_generator_valid(batch_size),\n",
        "    validation_steps = 100,\n",
        "    steps_per_epoch=100,\n",
        "    epochs=epochs,\n",
        "    verbose=1, \n",
        "    shuffle=True,\n",
        "    callbacks = callback_list,\n",
        "    # class_weight = cls_w,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6AdzICIAnvV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}