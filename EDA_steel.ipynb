{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EDA steel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/secutron/ShowTime/blob/master/EDA_steel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfwXQ6XwFyCv",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3Ch9kfQbqbf",
        "colab_type": "text"
      },
      "source": [
        "## Connect with Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNRMqv4Yl38F",
        "colab_type": "code",
        "outputId": "1103e661-4cbd-40e2-c810-5872570163f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laENh7RRb3An",
        "colab_type": "text"
      },
      "source": [
        "## Set Directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZpcGH6BmCk8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/My Drive/dataset/Steel/steel1/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iT5C1UupkDbI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!ls ./test_images/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwRYBDe1cKhv",
        "colab_type": "text"
      },
      "source": [
        "## Import required packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M350W7LvmD8Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "34099e46-228c-4abf-f221-8dbeb094ebaf"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers import Activation, Lambda, GlobalAveragePooling2D, concatenate\n",
        "from tensorflow.keras.layers import UpSampling2D, Conv2D, Dropout, MaxPooling2D, Conv2DTranspose\n",
        "from tensorflow.keras.layers import Dense, Flatten, Input\n",
        "from tensorflow.keras.models import Model, Sequential, load_model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "# from tensorflow.keras.applications.vgg16 import VGG16\n",
        "# from keras.applications.vgg16 import VGG16\n",
        "# from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import pickle"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_M1A244cOl3",
        "colab_type": "text"
      },
      "source": [
        "## Hyperparameters\n",
        "\n",
        "원영상 크기는 1600x256x24b"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7Cv_aPTmF8H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_size = 256\n",
        "IMG_HEIGHT = 400\n",
        "IMG_WIDTH = 1600\n",
        "epochs = 10\n",
        "batch_size = 4\n",
        "model_name = 'Training Segementaion Unet 09-10-19.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vZIQYZ0cTP3",
        "colab_type": "text"
      },
      "source": [
        "## Read csv for traning and validation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O70VYMNvPDim",
        "colab_type": "code",
        "outputId": "a433480e-498f-4e6b-8399-e1847863357c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "tr = pd.read_csv('train.csv')\n",
        "tr.head()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ImageId</th>\n",
              "      <th>ClassId</th>\n",
              "      <th>EncodedPixels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0002cc93b.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>29102 12 29346 24 29602 24 29858 24 30114 24 3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0007a71bf.jpg</td>\n",
              "      <td>3</td>\n",
              "      <td>18661 28 18863 82 19091 110 19347 110 19603 11...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000a4bcdd.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>37607 3 37858 8 38108 14 38359 20 38610 25 388...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000f6bf48.jpg</td>\n",
              "      <td>4</td>\n",
              "      <td>131973 1 132228 4 132483 6 132738 8 132993 11 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0014fce06.jpg</td>\n",
              "      <td>3</td>\n",
              "      <td>229501 11 229741 33 229981 55 230221 77 230468...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         ImageId  ClassId                                      EncodedPixels\n",
              "0  0002cc93b.jpg        1  29102 12 29346 24 29602 24 29858 24 30114 24 3...\n",
              "1  0007a71bf.jpg        3  18661 28 18863 82 19091 110 19347 110 19603 11...\n",
              "2  000a4bcdd.jpg        1  37607 3 37858 8 38108 14 38359 20 38610 25 388...\n",
              "3  000f6bf48.jpg        4  131973 1 132228 4 132483 6 132738 8 132993 11 ...\n",
              "4  0014fce06.jpg        3  229501 11 229741 33 229981 55 230221 77 230468..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fd6-O2LHw1Z6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "c5da640c-1f03-4c38-da81-33be81aa6c3e"
      },
      "source": [
        "tr.info()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7095 entries, 0 to 7094\n",
            "Data columns (total 3 columns):\n",
            " #   Column         Non-Null Count  Dtype \n",
            "---  ------         --------------  ----- \n",
            " 0   ImageId        7095 non-null   object\n",
            " 1   ClassId        7095 non-null   int64 \n",
            " 2   EncodedPixels  7095 non-null   object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 166.4+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ff92uuUYmrOD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "outputId": "fcb0beff-7a9f-4719-84c5-71104d8a99c8"
      },
      "source": [
        "class_count = defaultdict(int)\n",
        "\n",
        "for row in range(0, len(tr)):\n",
        "  labels = tr.iloc[row, 1]\n",
        "  class_count[labels] += 1;\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "sns.barplot(x=list(class_count.keys()), y=list(class_count.values()), ax=ax)\n",
        "ax.set_title(\"the number of images for each class\")\n",
        "ax.set_xlabel(\"class\")\n",
        "class_dict\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(int, {})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A674_CqWjbsF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "099e6b0c-6d97-4fbf-a765-cda458875dfc"
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-d81212bca616>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mimg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mimg_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mimg_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mimg_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLaIl796kTNr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEE5qilBmVSo",
        "colab_type": "code",
        "outputId": "bcb69ee1-082d-4af8-bbb0-7b5d05bb7778",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df_train = tr[tr['EncodedPixels'].notnull()].reset_index(drop=True)\n",
        "df_train.head()\n",
        "\n",
        "#df_val = te[te['EncodedPixels'].notnull()].reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ImageId</th>\n",
              "      <th>ClassId</th>\n",
              "      <th>EncodedPixels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0002cc93b.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>29102 12 29346 24 29602 24 29858 24 30114 24 3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0007a71bf.jpg</td>\n",
              "      <td>3</td>\n",
              "      <td>18661 28 18863 82 19091 110 19347 110 19603 11...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000a4bcdd.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>37607 3 37858 8 38108 14 38359 20 38610 25 388...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000f6bf48.jpg</td>\n",
              "      <td>4</td>\n",
              "      <td>131973 1 132228 4 132483 6 132738 8 132993 11 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0014fce06.jpg</td>\n",
              "      <td>3</td>\n",
              "      <td>229501 11 229741 33 229981 55 230221 77 230468...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         ImageId  ClassId                                      EncodedPixels\n",
              "0  0002cc93b.jpg        1  29102 12 29346 24 29602 24 29858 24 30114 24 3...\n",
              "1  0007a71bf.jpg        3  18661 28 18863 82 19091 110 19347 110 19603 11...\n",
              "2  000a4bcdd.jpg        1  37607 3 37858 8 38108 14 38359 20 38610 25 388...\n",
              "3  000f6bf48.jpg        4  131973 1 132228 4 132483 6 132738 8 132993 11 ...\n",
              "4  0014fce06.jpg        3  229501 11 229741 33 229981 55 230221 77 230468..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5O2nHh5cn1B",
        "colab_type": "text"
      },
      "source": [
        "## Runlength encoding for masking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "by8GVtximXex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rle2mask(rle, imgshape):\n",
        "    width = imgshape[0]\n",
        "    height= imgshape[1]\n",
        "    \n",
        "    mask= np.zeros( width*height ).astype(np.uint8)\n",
        "    \n",
        "    array = np.asarray([int(x) for x in rle.split()])\n",
        "    starts = array[0::2]\n",
        "    lengths = array[1::2]\n",
        "\n",
        "    current_position = 0\n",
        "    for index, start in enumerate(starts):\n",
        "        mask[int(start):int(start+lengths[index])] = 1\n",
        "        current_position += lengths[index]\n",
        "        \n",
        "    return np.flipud( np.rot90( mask.reshape(height, width), k=1 ) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVVvQaBLcwaS",
        "colab_type": "text"
      },
      "source": [
        "## Data Generator Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uz-nx2pYmZNI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def keras_generator_train(batch_size):\n",
        "    while True:\n",
        "        x_batch = []\n",
        "        img_cls_list = []\n",
        "        mask_list = []\n",
        "        classification_list = []\n",
        "        \n",
        "        for i in range(batch_size):            \n",
        "            fn = df_train['ImageId_ClassId'].iloc[i].split('_')[0]\n",
        "            img = cv2.imread('dataset/train_images/'+fn )\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  \n",
        "\n",
        "            # print(\"Shape: \", img.shape)          \n",
        "            \n",
        "            mask = rle2mask(df_train['EncodedPixels'].iloc[i], img.shape)\n",
        "            \n",
        "            # img = cv2.resize(img, (image_size, image_size))\n",
        "            # mask = cv2.resize(mask, (image_size, image_size))\n",
        "\n",
        "            img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n",
        "            mask = cv2.resize(mask, (IMG_WIDTH, IMG_HEIGHT))\n",
        "            mask = np.reshape(mask, (mask.shape[0], mask.shape[1], 1))\n",
        "\n",
        "            \n",
        "            # img_cls = df_train['ImageId_ClassId'].iloc[i].split('_')[1]\n",
        "            # if img_cls == '1':\n",
        "            #     img_cls_list = np.array([1, 0, 0, 0])\n",
        "            # elif img_cls == '2':\n",
        "            #     img_cls_list = np.array([0, 1, 0, 0])\n",
        "            # elif img_cls == '3':\n",
        "            #     img_cls_list = np.array([0, 0, 1, 0])\n",
        "            # else:\n",
        "            #     img_cls_list = np.array([0, 0, 0, 1])\n",
        "\n",
        "\n",
        "\n",
        "            x_batch.append(img)\n",
        "            mask_list.append(mask)\n",
        "            # classification_list.append(img_cls_list)\n",
        "        \n",
        "        y_batch = {'seg': np.array(mask_list),\n",
        "                #    'cls': np.array(classification_list)\n",
        "                }\n",
        "           \n",
        "        x_batch = np.array(x_batch)\n",
        "\n",
        "        yield x_batch, y_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CW0WJms3czop",
        "colab_type": "text"
      },
      "source": [
        "## Data Generator Valid"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edeX8uVBmbgw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def keras_generator_valid(batch_size):\n",
        "    while True:\n",
        "        x_batch = []\n",
        "        img_cls_list = []\n",
        "        mask_list = []\n",
        "        classification_list = []\n",
        "        \n",
        "        for i in range(batch_size):            \n",
        "            fn = df_val['ImageId_ClassId'].iloc[i].split('_')[0]\n",
        "            img = cv2.imread( 'dataset/valid_images/'+fn )\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)            \n",
        "            \n",
        "            mask = rle2mask(df_train['EncodedPixels'].iloc[i], img.shape)\n",
        "            \n",
        "            # img = cv2.resize(img, (image_size, image_size))\n",
        "            # mask = cv2.resize(mask, (image_size, image_size))\n",
        "\n",
        "            img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n",
        "            mask = cv2.resize(mask, (IMG_WIDTH, IMG_HEIGHT))\n",
        "\n",
        "            mask = np.reshape(mask, (mask.shape[0], mask.shape[1], 1))\n",
        "            \n",
        "            # img_cls = df_train['ImageId_ClassId'].iloc[i].split('_')[1]\n",
        "            # if img_cls == '1':\n",
        "            #     img_cls_list = np.array([1, 0, 0, 0])\n",
        "            # elif img_cls == '2':\n",
        "            #     img_cls_list = np.array([0, 1, 0, 0])\n",
        "            # elif img_cls == '3':\n",
        "            #     img_cls_list = np.array([0, 0, 1, 0])\n",
        "            # else:\n",
        "            #     img_cls_list = np.array([0, 0, 0, 1])\n",
        "            \n",
        "            x_batch.append(img)\n",
        "            mask_list.append(mask)\n",
        "            # classification_list.append(img_cls_list)\n",
        "        \n",
        "        y_batch = {'seg': np.array(mask_list),\n",
        "                #    'cls': np.array(classification_list)\n",
        "                }\n",
        "           \n",
        "        x_batch = np.array(x_batch)\n",
        "        \n",
        "        yield x_batch, y_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZXLgpSu8z7O",
        "colab_type": "code",
        "outputId": "febb0c5b-6a71-48b2-fd15-d605803d1874",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "for xcls, ycls in keras_generator_train(5):\n",
        "    break\n",
        "    \n",
        "print(xcls.shape)\n",
        "print(ycls['seg'].shape)\n",
        "# print(ycls['cls'].shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5, 400, 1600, 3)\n",
            "(5, 400, 1600, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXqTxKsEAZra",
        "colab_type": "code",
        "outputId": "a6e048b0-2308-41cc-eb10-c87e3443b0c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "for xcls, ycls in keras_generator_valid(5):\n",
        "    break\n",
        "    \n",
        "print(xcls.shape)\n",
        "print(ycls['seg'].shape)\n",
        "# print(ycls['cls'].shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5, 400, 1600, 3)\n",
            "(5, 400, 1600, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8w9gtsHc7R6",
        "colab_type": "text"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuElNADYmcIB",
        "colab_type": "code",
        "outputId": "fd2078d8-b209-4ce6-8d04-01486feb8153",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "# in1 = Input(shape=(image_size, image_size, 3 ))\n",
        "\n",
        "in1 = Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3 ))\n",
        "\n",
        "conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(in1)\n",
        "conv1 = Dropout(0.2)(conv1)\n",
        "conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
        "pool1 = MaxPooling2D((2, 2))(conv1)\n",
        "\n",
        "conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
        "conv2 = Dropout(0.2)(conv2)\n",
        "conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
        "pool2 = MaxPooling2D((2, 2))(conv2)\n",
        "\n",
        "conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
        "conv3 = Dropout(0.2)(conv3)\n",
        "conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
        "\n",
        "up1 = concatenate([UpSampling2D((2, 2))(conv3), conv2], axis=-1)\n",
        "conv4 = Conv2D(64, (3, 3), activation='relu', padding='same')(up1)\n",
        "conv4 = Dropout(0.2)(conv4)\n",
        "conv4 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv4)\n",
        "\n",
        "up2 = concatenate([UpSampling2D((2, 2))(conv4), conv1], axis=-1)\n",
        "conv5 = Conv2D(32, (3, 3), activation='relu', padding='same')(up2)\n",
        "conv5 = Dropout(0.2)(conv5)\n",
        "conv5 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv5)\n",
        "segmentation = Conv2D(1, (1, 1), activation='sigmoid', name='seg')(conv5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNQKPFBvmm6C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(inputs=[in1], outputs=[segmentation])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sVWwZuwc_dB",
        "colab_type": "text"
      },
      "source": [
        "## Parameters for compilation of model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uW8orbQFvSTx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "losses = {'seg': 'binary_crossentropy'\n",
        "            }\n",
        "\n",
        "metrics = {'seg': ['acc']\n",
        "            }\n",
        "\n",
        "# cls_w = {'seg': {0: 1.0, \n",
        "#                  1: 1.5647207819029325, \n",
        "#                  2: 1.0, \n",
        "#                  3: 1.0}\n",
        "#         }\n",
        "\n",
        "moni = {'seg': ['val_loss']\n",
        "        }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fzqirHhdGc5",
        "colab_type": "text"
      },
      "source": [
        "## Compile"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNbL_7Fwu02t",
        "colab_type": "code",
        "outputId": "ea6b2e1b-812d-4c8f-b889-18fea2a911fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "model.compile(optimizer=\"adam\", loss = losses, metrics=metrics)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2FVTkVxdI0J",
        "colab_type": "text"
      },
      "source": [
        "## Fit Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDfwlREev7vO",
        "colab_type": "code",
        "outputId": "43577ea4-f8ba-49d4-b29d-3ccd8bb6f705",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "modelcheckpoint = ModelCheckpoint(model_name,\n",
        "                                  monitor='acc',\n",
        "                                  mode='auto',\n",
        "                                  verbose=1,\n",
        "                                  save_best_only=True)\n",
        "\n",
        "lr_callback = ReduceLROnPlateau(min_lr=0.000001)\n",
        "\n",
        "callback_list = [modelcheckpoint, lr_callback]\n",
        "\n",
        "history = model.fit_generator(\n",
        "    keras_generator_train(batch_size),\n",
        "    validation_data = keras_generator_valid(batch_size),\n",
        "    validation_steps = 100,\n",
        "    steps_per_epoch=100,\n",
        "    epochs=epochs,\n",
        "    verbose=1, \n",
        "    shuffle=True,\n",
        "    callbacks = callback_list,\n",
        "    # class_weight = cls_w,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            " 99/100 [============================>.] - ETA: 1s - loss: 0.2032 - acc: 0.9463Epoch 1/10\n",
            "100/100 [==============================] - 43s 430ms/step - loss: 0.2712 - acc: 0.9467\n",
            "\n",
            "Epoch 00001: acc improved from -inf to 0.94634, saving model to Training Segementaion Unet 09-10-19.h5\n",
            "100/100 [==============================] - 176s 2s/step - loss: 0.2031 - acc: 0.9463 - val_loss: 0.2712 - val_acc: 0.9467\n",
            "Epoch 2/10\n",
            " 99/100 [============================>.] - ETA: 1s - loss: 0.1912 - acc: 0.9469Epoch 1/10\n",
            "100/100 [==============================] - 43s 430ms/step - loss: 0.2828 - acc: 0.9445\n",
            "\n",
            "Epoch 00002: acc improved from 0.94634 to 0.94695, saving model to Training Segementaion Unet 09-10-19.h5\n",
            "100/100 [==============================] - 176s 2s/step - loss: 0.1912 - acc: 0.9469 - val_loss: 0.2828 - val_acc: 0.9445\n",
            "Epoch 3/10\n",
            " 99/100 [============================>.] - ETA: 1s - loss: 0.1566 - acc: 0.9471Epoch 1/10\n",
            "100/100 [==============================] - 43s 430ms/step - loss: 0.3188 - acc: 0.9394\n",
            "\n",
            "Epoch 00003: acc improved from 0.94695 to 0.94713, saving model to Training Segementaion Unet 09-10-19.h5\n",
            "100/100 [==============================] - 176s 2s/step - loss: 0.1564 - acc: 0.9471 - val_loss: 0.3188 - val_acc: 0.9394\n",
            "Epoch 4/10\n",
            " 99/100 [============================>.] - ETA: 1s - loss: 0.1180 - acc: 0.9519Epoch 1/10\n",
            "100/100 [==============================] - 43s 435ms/step - loss: 0.4546 - acc: 0.9186\n",
            "\n",
            "Epoch 00004: acc improved from 0.94713 to 0.95192, saving model to Training Segementaion Unet 09-10-19.h5\n",
            "100/100 [==============================] - 177s 2s/step - loss: 0.1179 - acc: 0.9519 - val_loss: 0.4546 - val_acc: 0.9186\n",
            "Epoch 5/10\n",
            " 99/100 [============================>.] - ETA: 1s - loss: 0.1074 - acc: 0.9561Epoch 1/10\n",
            "100/100 [==============================] - 44s 437ms/step - loss: 0.4576 - acc: 0.9296\n",
            "\n",
            "Epoch 00005: acc improved from 0.95192 to 0.95612, saving model to Training Segementaion Unet 09-10-19.h5\n",
            "100/100 [==============================] - 178s 2s/step - loss: 0.1074 - acc: 0.9561 - val_loss: 0.4576 - val_acc: 0.9296\n",
            "Epoch 6/10\n",
            " 99/100 [============================>.] - ETA: 1s - loss: 0.1004 - acc: 0.9594Epoch 1/10\n",
            "100/100 [==============================] - 44s 436ms/step - loss: 0.5518 - acc: 0.8954\n",
            "\n",
            "Epoch 00006: acc improved from 0.95612 to 0.95944, saving model to Training Segementaion Unet 09-10-19.h5\n",
            "100/100 [==============================] - 178s 2s/step - loss: 0.1003 - acc: 0.9594 - val_loss: 0.5518 - val_acc: 0.8954\n",
            "Epoch 7/10\n",
            " 99/100 [============================>.] - ETA: 1s - loss: 0.0927 - acc: 0.9631Epoch 1/10\n",
            "100/100 [==============================] - 44s 436ms/step - loss: 0.5566 - acc: 0.9121\n",
            "\n",
            "Epoch 00007: acc improved from 0.95944 to 0.96304, saving model to Training Segementaion Unet 09-10-19.h5\n",
            "100/100 [==============================] - 178s 2s/step - loss: 0.0928 - acc: 0.9630 - val_loss: 0.5566 - val_acc: 0.9121\n",
            "Epoch 8/10\n",
            " 99/100 [============================>.] - ETA: 1s - loss: 0.0871 - acc: 0.9661Epoch 1/10\n",
            "100/100 [==============================] - 44s 437ms/step - loss: 0.7148 - acc: 0.8931\n",
            "\n",
            "Epoch 00008: acc improved from 0.96304 to 0.96610, saving model to Training Segementaion Unet 09-10-19.h5\n",
            "100/100 [==============================] - 178s 2s/step - loss: 0.0871 - acc: 0.9661 - val_loss: 0.7148 - val_acc: 0.8931\n",
            "Epoch 9/10\n",
            " 99/100 [============================>.] - ETA: 1s - loss: 0.0754 - acc: 0.9716Epoch 1/10\n",
            "100/100 [==============================] - 44s 436ms/step - loss: 1.0286 - acc: 0.8700\n",
            "\n",
            "Epoch 00009: acc improved from 0.96610 to 0.97164, saving model to Training Segementaion Unet 09-10-19.h5\n",
            "100/100 [==============================] - 178s 2s/step - loss: 0.0753 - acc: 0.9716 - val_loss: 1.0286 - val_acc: 0.8700\n",
            "Epoch 10/10\n",
            " 99/100 [============================>.] - ETA: 1s - loss: 0.0631 - acc: 0.9771Epoch 1/10\n",
            "100/100 [==============================] - 44s 439ms/step - loss: 1.0112 - acc: 0.8720\n",
            "\n",
            "Epoch 00010: acc improved from 0.97164 to 0.97708, saving model to Training Segementaion Unet 09-10-19.h5\n",
            "100/100 [==============================] - 179s 2s/step - loss: 0.0630 - acc: 0.9771 - val_loss: 1.0112 - val_acc: 0.8720\n",
            "CPU times: user 13min 48s, sys: 5min 23s, total: 19min 11s\n",
            "Wall time: 29min 33s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6AdzICIAnvV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}