{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EDA steel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/secutron/ShowTime/blob/master/EDA_steel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfwXQ6XwFyCv",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3Ch9kfQbqbf",
        "colab_type": "text"
      },
      "source": [
        "## Connect with Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNRMqv4Yl38F",
        "colab_type": "code",
        "outputId": "05f0e6a8-849f-49da-8e8e-f4042ee8461f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laENh7RRb3An",
        "colab_type": "text"
      },
      "source": [
        "## Set Directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZpcGH6BmCk8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/My Drive/Projects/Steel Defect Detection/try 3000/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwRYBDe1cKhv",
        "colab_type": "text"
      },
      "source": [
        "## Import required packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M350W7LvmD8Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers import Activation, Lambda, GlobalAveragePooling2D, concatenate\n",
        "from tensorflow.keras.layers import UpSampling2D, Conv2D, Dropout, MaxPooling2D, Conv2DTranspose\n",
        "from tensorflow.keras.layers import Dense, Flatten, Input\n",
        "from tensorflow.keras.models import Model, Sequential, load_model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "# from tensorflow.keras.applications.vgg16 import VGG16\n",
        "# from keras.applications.vgg16 import VGG16\n",
        "# from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_M1A244cOl3",
        "colab_type": "text"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7Cv_aPTmF8H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_size = 256\n",
        "IMG_HEIGHT = 400\n",
        "IMG_WIDTH = 1600\n",
        "epochs = 10\n",
        "batch_size = 4\n",
        "model_name = 'Training Segementaion Unet 09-10-19.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vZIQYZ0cTP3",
        "colab_type": "text"
      },
      "source": [
        "## Read csv for traning and validation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEE5qilBmVSo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tr = pd.read_csv('dataset/train1.csv')\n",
        "te = pd.read_csv('dataset/val1.csv')\n",
        "df_train = tr[tr['EncodedPixels'].notnull()].reset_index(drop=True)\n",
        "df_val = te[te['EncodedPixels'].notnull()].reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5O2nHh5cn1B",
        "colab_type": "text"
      },
      "source": [
        "## Runlength encoding for masking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "by8GVtximXex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rle2mask(rle, imgshape):\n",
        "    width = imgshape[0]\n",
        "    height= imgshape[1]\n",
        "    \n",
        "    mask= np.zeros( width*height ).astype(np.uint8)\n",
        "    \n",
        "    array = np.asarray([int(x) for x in rle.split()])\n",
        "    starts = array[0::2]\n",
        "    lengths = array[1::2]\n",
        "\n",
        "    current_position = 0\n",
        "    for index, start in enumerate(starts):\n",
        "        mask[int(start):int(start+lengths[index])] = 1\n",
        "        current_position += lengths[index]\n",
        "        \n",
        "    return np.flipud( np.rot90( mask.reshape(height, width), k=1 ) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVVvQaBLcwaS",
        "colab_type": "text"
      },
      "source": [
        "## Data Generator Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uz-nx2pYmZNI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def keras_generator_train(batch_size):\n",
        "    while True:\n",
        "        x_batch = []\n",
        "        img_cls_list = []\n",
        "        mask_list = []\n",
        "        classification_list = []\n",
        "        \n",
        "        for i in range(batch_size):            \n",
        "            fn = df_train['ImageId_ClassId'].iloc[i].split('_')[0]\n",
        "            img = cv2.imread('dataset/train_images/'+fn )\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  \n",
        "\n",
        "            # print(\"Shape: \", img.shape)          \n",
        "            \n",
        "            mask = rle2mask(df_train['EncodedPixels'].iloc[i], img.shape)\n",
        "            \n",
        "            # img = cv2.resize(img, (image_size, image_size))\n",
        "            # mask = cv2.resize(mask, (image_size, image_size))\n",
        "\n",
        "            img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n",
        "            mask = cv2.resize(mask, (IMG_WIDTH, IMG_HEIGHT))\n",
        "            mask = np.reshape(mask, (mask.shape[0], mask.shape[1], 1))\n",
        "\n",
        "            \n",
        "            # img_cls = df_train['ImageId_ClassId'].iloc[i].split('_')[1]\n",
        "            # if img_cls == '1':\n",
        "            #     img_cls_list = np.array([1, 0, 0, 0])\n",
        "            # elif img_cls == '2':\n",
        "            #     img_cls_list = np.array([0, 1, 0, 0])\n",
        "            # elif img_cls == '3':\n",
        "            #     img_cls_list = np.array([0, 0, 1, 0])\n",
        "            # else:\n",
        "            #     img_cls_list = np.array([0, 0, 0, 1])\n",
        "\n",
        "\n",
        "\n",
        "            x_batch.append(img)\n",
        "            mask_list.append(mask)\n",
        "            # classification_list.append(img_cls_list)\n",
        "        \n",
        "        y_batch = {'seg': np.array(mask_list),\n",
        "                #    'cls': np.array(classification_list)\n",
        "                }\n",
        "           \n",
        "        x_batch = np.array(x_batch)\n",
        "\n",
        "        yield x_batch, y_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CW0WJms3czop",
        "colab_type": "text"
      },
      "source": [
        "## Data Generator Valid"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edeX8uVBmbgw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def keras_generator_valid(batch_size):\n",
        "    while True:\n",
        "        x_batch = []\n",
        "        img_cls_list = []\n",
        "        mask_list = []\n",
        "        classification_list = []\n",
        "        \n",
        "        for i in range(batch_size):            \n",
        "            fn = df_val['ImageId_ClassId'].iloc[i].split('_')[0]\n",
        "            img = cv2.imread( 'dataset/valid_images/'+fn )\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)            \n",
        "            \n",
        "            mask = rle2mask(df_train['EncodedPixels'].iloc[i], img.shape)\n",
        "            \n",
        "            # img = cv2.resize(img, (image_size, image_size))\n",
        "            # mask = cv2.resize(mask, (image_size, image_size))\n",
        "\n",
        "            img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n",
        "            mask = cv2.resize(mask, (IMG_WIDTH, IMG_HEIGHT))\n",
        "\n",
        "            mask = np.reshape(mask, (mask.shape[0], mask.shape[1], 1))\n",
        "            \n",
        "            # img_cls = df_train['ImageId_ClassId'].iloc[i].split('_')[1]\n",
        "            # if img_cls == '1':\n",
        "            #     img_cls_list = np.array([1, 0, 0, 0])\n",
        "            # elif img_cls == '2':\n",
        "            #     img_cls_list = np.array([0, 1, 0, 0])\n",
        "            # elif img_cls == '3':\n",
        "            #     img_cls_list = np.array([0, 0, 1, 0])\n",
        "            # else:\n",
        "            #     img_cls_list = np.array([0, 0, 0, 1])\n",
        "            \n",
        "            x_batch.append(img)\n",
        "            mask_list.append(mask)\n",
        "            # classification_list.append(img_cls_list)\n",
        "        \n",
        "        y_batch = {'seg': np.array(mask_list),\n",
        "                #    'cls': np.array(classification_list)\n",
        "                }\n",
        "           \n",
        "        x_batch = np.array(x_batch)\n",
        "        \n",
        "        yield x_batch, y_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZXLgpSu8z7O",
        "colab_type": "code",
        "outputId": "febb0c5b-6a71-48b2-fd15-d605803d1874",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "for xcls, ycls in keras_generator_train(5):\n",
        "    break\n",
        "    \n",
        "print(xcls.shape)\n",
        "print(ycls['seg'].shape)\n",
        "# print(ycls['cls'].shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5, 400, 1600, 3)\n",
            "(5, 400, 1600, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXqTxKsEAZra",
        "colab_type": "code",
        "outputId": "a6e048b0-2308-41cc-eb10-c87e3443b0c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "for xcls, ycls in keras_generator_valid(5):\n",
        "    break\n",
        "    \n",
        "print(xcls.shape)\n",
        "print(ycls['seg'].shape)\n",
        "# print(ycls['cls'].shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5, 400, 1600, 3)\n",
            "(5, 400, 1600, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8w9gtsHc7R6",
        "colab_type": "text"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuElNADYmcIB",
        "colab_type": "code",
        "outputId": "fd2078d8-b209-4ce6-8d04-01486feb8153",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "# in1 = Input(shape=(image_size, image_size, 3 ))\n",
        "\n",
        "in1 = Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3 ))\n",
        "\n",
        "conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(in1)\n",
        "conv1 = Dropout(0.2)(conv1)\n",
        "conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
        "pool1 = MaxPooling2D((2, 2))(conv1)\n",
        "\n",
        "conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
        "conv2 = Dropout(0.2)(conv2)\n",
        "conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
        "pool2 = MaxPooling2D((2, 2))(conv2)\n",
        "\n",
        "conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
        "conv3 = Dropout(0.2)(conv3)\n",
        "conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
        "\n",
        "up1 = concatenate([UpSampling2D((2, 2))(conv3), conv2], axis=-1)\n",
        "conv4 = Conv2D(64, (3, 3), activation='relu', padding='same')(up1)\n",
        "conv4 = Dropout(0.2)(conv4)\n",
        "conv4 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv4)\n",
        "\n",
        "up2 = concatenate([UpSampling2D((2, 2))(conv4), conv1], axis=-1)\n",
        "conv5 = Conv2D(32, (3, 3), activation='relu', padding='same')(up2)\n",
        "conv5 = Dropout(0.2)(conv5)\n",
        "conv5 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv5)\n",
        "segmentation = Conv2D(1, (1, 1), activation='sigmoid', name='seg')(conv5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNQKPFBvmm6C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(inputs=[in1], outputs=[segmentation])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sVWwZuwc_dB",
        "colab_type": "text"
      },
      "source": [
        "## Parameters for compilation of model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uW8orbQFvSTx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "losses = {'seg': 'binary_crossentropy'\n",
        "            }\n",
        "\n",
        "metrics = {'seg': ['acc']\n",
        "            }\n",
        "\n",
        "# cls_w = {'seg': {0: 1.0, \n",
        "#                  1: 1.5647207819029325, \n",
        "#                  2: 1.0, \n",
        "#                  3: 1.0}\n",
        "#         }\n",
        "\n",
        "moni = {'seg': ['val_loss']\n",
        "        }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fzqirHhdGc5",
        "colab_type": "text"
      },
      "source": [
        "## Compile"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNbL_7Fwu02t",
        "colab_type": "code",
        "outputId": "ea6b2e1b-812d-4c8f-b889-18fea2a911fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "model.compile(optimizer=\"adam\", loss = losses, metrics=metrics)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2FVTkVxdI0J",
        "colab_type": "text"
      },
      "source": [
        "## Fit Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDfwlREev7vO",
        "colab_type": "code",
        "outputId": "43577ea4-f8ba-49d4-b29d-3ccd8bb6f705",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "modelcheckpoint = ModelCheckpoint(model_name,\n",
        "                                  monitor='acc',\n",
        "                                  mode='auto',\n",
        "                                  verbose=1,\n",
        "                                  save_best_only=True)\n",
        "\n",
        "lr_callback = ReduceLROnPlateau(min_lr=0.000001)\n",
        "\n",
        "callback_list = [modelcheckpoint, lr_callback]\n",
        "\n",
        "history = model.fit_generator(\n",
        "    keras_generator_train(batch_size),\n",
        "    validation_data = keras_generator_valid(batch_size),\n",
        "    validation_steps = 100,\n",
        "    steps_per_epoch=100,\n",
        "    epochs=epochs,\n",
        "    verbose=1, \n",
        "    shuffle=True,\n",
        "    callbacks = callback_list,\n",
        "    # class_weight = cls_w,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            " 99/100 [============================>.] - ETA: 1s - loss: 0.2032 - acc: 0.9463Epoch 1/10\n",
            "100/100 [==============================] - 43s 430ms/step - loss: 0.2712 - acc: 0.9467\n",
            "\n",
            "Epoch 00001: acc improved from -inf to 0.94634, saving model to Training Segementaion Unet 09-10-19.h5\n",
            "100/100 [==============================] - 176s 2s/step - loss: 0.2031 - acc: 0.9463 - val_loss: 0.2712 - val_acc: 0.9467\n",
            "Epoch 2/10\n",
            " 99/100 [============================>.] - ETA: 1s - loss: 0.1912 - acc: 0.9469Epoch 1/10\n",
            "100/100 [==============================] - 43s 430ms/step - loss: 0.2828 - acc: 0.9445\n",
            "\n",
            "Epoch 00002: acc improved from 0.94634 to 0.94695, saving model to Training Segementaion Unet 09-10-19.h5\n",
            "100/100 [==============================] - 176s 2s/step - loss: 0.1912 - acc: 0.9469 - val_loss: 0.2828 - val_acc: 0.9445\n",
            "Epoch 3/10\n",
            " 99/100 [============================>.] - ETA: 1s - loss: 0.1566 - acc: 0.9471Epoch 1/10\n",
            "100/100 [==============================] - 43s 430ms/step - loss: 0.3188 - acc: 0.9394\n",
            "\n",
            "Epoch 00003: acc improved from 0.94695 to 0.94713, saving model to Training Segementaion Unet 09-10-19.h5\n",
            "100/100 [==============================] - 176s 2s/step - loss: 0.1564 - acc: 0.9471 - val_loss: 0.3188 - val_acc: 0.9394\n",
            "Epoch 4/10\n",
            " 99/100 [============================>.] - ETA: 1s - loss: 0.1180 - acc: 0.9519Epoch 1/10\n",
            "100/100 [==============================] - 43s 435ms/step - loss: 0.4546 - acc: 0.9186\n",
            "\n",
            "Epoch 00004: acc improved from 0.94713 to 0.95192, saving model to Training Segementaion Unet 09-10-19.h5\n",
            "100/100 [==============================] - 177s 2s/step - loss: 0.1179 - acc: 0.9519 - val_loss: 0.4546 - val_acc: 0.9186\n",
            "Epoch 5/10\n",
            " 99/100 [============================>.] - ETA: 1s - loss: 0.1074 - acc: 0.9561Epoch 1/10\n",
            "100/100 [==============================] - 44s 437ms/step - loss: 0.4576 - acc: 0.9296\n",
            "\n",
            "Epoch 00005: acc improved from 0.95192 to 0.95612, saving model to Training Segementaion Unet 09-10-19.h5\n",
            "100/100 [==============================] - 178s 2s/step - loss: 0.1074 - acc: 0.9561 - val_loss: 0.4576 - val_acc: 0.9296\n",
            "Epoch 6/10\n",
            " 99/100 [============================>.] - ETA: 1s - loss: 0.1004 - acc: 0.9594Epoch 1/10\n",
            "100/100 [==============================] - 44s 436ms/step - loss: 0.5518 - acc: 0.8954\n",
            "\n",
            "Epoch 00006: acc improved from 0.95612 to 0.95944, saving model to Training Segementaion Unet 09-10-19.h5\n",
            "100/100 [==============================] - 178s 2s/step - loss: 0.1003 - acc: 0.9594 - val_loss: 0.5518 - val_acc: 0.8954\n",
            "Epoch 7/10\n",
            " 99/100 [============================>.] - ETA: 1s - loss: 0.0927 - acc: 0.9631Epoch 1/10\n",
            "100/100 [==============================] - 44s 436ms/step - loss: 0.5566 - acc: 0.9121\n",
            "\n",
            "Epoch 00007: acc improved from 0.95944 to 0.96304, saving model to Training Segementaion Unet 09-10-19.h5\n",
            "100/100 [==============================] - 178s 2s/step - loss: 0.0928 - acc: 0.9630 - val_loss: 0.5566 - val_acc: 0.9121\n",
            "Epoch 8/10\n",
            " 99/100 [============================>.] - ETA: 1s - loss: 0.0871 - acc: 0.9661Epoch 1/10\n",
            "100/100 [==============================] - 44s 437ms/step - loss: 0.7148 - acc: 0.8931\n",
            "\n",
            "Epoch 00008: acc improved from 0.96304 to 0.96610, saving model to Training Segementaion Unet 09-10-19.h5\n",
            "100/100 [==============================] - 178s 2s/step - loss: 0.0871 - acc: 0.9661 - val_loss: 0.7148 - val_acc: 0.8931\n",
            "Epoch 9/10\n",
            " 99/100 [============================>.] - ETA: 1s - loss: 0.0754 - acc: 0.9716Epoch 1/10\n",
            "100/100 [==============================] - 44s 436ms/step - loss: 1.0286 - acc: 0.8700\n",
            "\n",
            "Epoch 00009: acc improved from 0.96610 to 0.97164, saving model to Training Segementaion Unet 09-10-19.h5\n",
            "100/100 [==============================] - 178s 2s/step - loss: 0.0753 - acc: 0.9716 - val_loss: 1.0286 - val_acc: 0.8700\n",
            "Epoch 10/10\n",
            " 99/100 [============================>.] - ETA: 1s - loss: 0.0631 - acc: 0.9771Epoch 1/10\n",
            "100/100 [==============================] - 44s 439ms/step - loss: 1.0112 - acc: 0.8720\n",
            "\n",
            "Epoch 00010: acc improved from 0.97164 to 0.97708, saving model to Training Segementaion Unet 09-10-19.h5\n",
            "100/100 [==============================] - 179s 2s/step - loss: 0.0630 - acc: 0.9771 - val_loss: 1.0112 - val_acc: 0.8720\n",
            "CPU times: user 13min 48s, sys: 5min 23s, total: 19min 11s\n",
            "Wall time: 29min 33s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6AdzICIAnvV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}